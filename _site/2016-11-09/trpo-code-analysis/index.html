<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TRPO算法与代码解析</title>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css" type="text/css">
  <link rel="stylesheet" href="/assets/css/social-share-kit.css" type="text/css">

  <!-- Font -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">


  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Namiyao" href="/feed.xml" />
  <!-- Begin Jekyll SEO tag v2.0.0 -->
<title>TRPO算法与代码解析 - Namiyao</title>
<meta property="og:title" content="TRPO算法与代码解析" />
<meta name="description" content="推导Trust Region Policy Optimization算法，结合Tensorflow代码讲解算法实现细节" />
<meta property="og:description" content="推导Trust Region Policy Optimization算法，结合Tensorflow代码讲解算法实现细节" />
<link rel="canonical" href="http://localhost:4000/2016-11-09/trpo-code-analysis/" />
<meta property="og:url" content="http://localhost:4000/2016-11-09/trpo-code-analysis/" />
<meta property="og:site_name" content="Namiyao" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2016-11-09T00:00:00+08:00" />
<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "TRPO算法与代码解析",
    "datePublished": "2016-11-09T00:00:00+08:00",
    "description": "推导Trust Region Policy Optimization算法，结合Tensorflow代码讲解算法实现细节",
    "url": "http://localhost:4000/2016-11-09/trpo-code-analysis/"
  }
</script>
<!-- End Jekyll SEO tag -->


  <!-- Google Analytics -->

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', '', 'auto');
ga('send', 'pageview');

</script>


  
  <!-- Mathjax -->
  <script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
  <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
</head>

<body>
  <div class="content-container">
    <header>
  <h1 class="header-small">
    <a href="http://localhost:4000">Namiyao</a>
  </h1>
</header>
<div class="post">
  <h1 class="post-title">TRPO算法与代码解析</h1>
  <span class="post-date">
    <time>09 Nov 2016</time>
  </span>
  <div class="post-tag">
    <ul>
      
    </ul>
  </div>

  <h1 id="introduction">Introduction</h1>
<p><a href="http://karpathy.github.io/2016/05/31/rl/">Andrej Karpathy</a>指出，Policy Gradients (PG)是default的Reinforcement Learning (RL)算法。文章<a href="https://arxiv.org/abs/1604.06778">Benchmarking Deep Reinforcement Learning for Continuous Control</a>指出，Truncated Natural Policy Gradient (TNPG)算法，Trust Region Policy Optimization (TRPO)算法，Deep Deterministic Policy Gradient (DDPG)算法取得了最好的实验结果。除此之外，文章中未提到的
<a href="https://arxiv.org/abs/1602.01783">Asynchronous Advantage Actor-Critic (A3C)</a>算法的表现也超过了DQN。以上四种算法均属于PG。</p>

<p>DDPG算法与代码解析参考<a href="http://pemami4911.github.io/blog/2016/08/21/ddpg-rl.html">Deep Deterministic Policy Gradients in TensorFlow</a>。</p>

<p>TNPG与TRPO算法的区别仅在于TRPO用了<a href="https://en.wikipedia.org/wiki/Backtracking_line_search">Backtracking line search</a>来确定步长，确保目标函数有足够的优化，而TNPG并没有使用Backtracking line search。本文对TRPO算法与代码进行解析，TNPG只需要去掉Backtracking line search这一步即可。</p>

<p>关于TRPO算法的文章主要有两篇。文章<a href="https://arxiv.org/abs/1502.05477">Trust Region Policy Optimization</a>提出了TRPO算法。文章<a href="https://arxiv.org/abs/1506.02438">High-Dimensional Continuous Control using Generalized Advantage Estimation</a>使用Generalized Advantage Estimator (GAE)改进了TRPO算法。</p>

<p>本文使用Wojciech Zaremba的基于Tensorflow的<a href="https://github.com/wojzaremba/trpo">代码</a>。</p>

<h1 id="theory-and-code">Theory and Code</h1>

<h2 id="policy-gradients">Policy Gradients</h2>
<p>用函数来近似policy，记作 $\pi_{\theta}(a|s)$。目标函数为expected discounted reward，</p>

<script type="math/tex; mode=display">J(\theta)=E_{\pi_{\theta}}[\sum_{t=0}^{\infty}\gamma^{t}r_{t}]</script>

<p>要最大化目标函数 $J(\theta)$，最直接的想法就是使用<a href="http://sebastianruder.com/optimizing-gradient-descent/index.html">mini-batch gradient descent optimization algorithms</a>，需要计算 $\nabla_{\theta}J(\theta)$。可是我们连 $J(\theta)$ 的解析表达式都没有啊喂，要怎么算导数啊喂！幸好我们有 <strong>Policy Gradients Theorem</strong>，</p>

<script type="math/tex; mode=display">\nabla_{\theta}J(\theta)=E_{\pi_{\theta}}[\nabla_{\theta}log\pi_{\theta}(a|s)Q^{\pi_{\theta}}(s,a)]</script>

<p>用advantage function代替state-action value function，容易证明上式仍然成立，</p>

<script type="math/tex; mode=display">\nabla_{\theta}J(\theta)=E_{\pi_{\theta}}[\nabla_{\theta}log\pi_{\theta}(a|s)A^{\pi_{\theta}}(s,a)]</script>

<p>其中   $A^{\pi_{\theta}}(s,a)=Q^{\pi_{\theta}}(s,a)-V^{\pi_{\theta}}(s)$。</p>

<p>现在 $\nabla_{\theta}J(\theta)$ 好算多了！只需要知道 $A^{\pi_{\theta}}(s,a)$ 就行了！记 $\hat A_{t}$ 为 $A^{\pi_{\theta}}(s_{t},a_{t})$ 的估计，则policy gradient estimator为</p>

<script type="math/tex; mode=display">\widehat{\nabla_{\theta}J(\theta)}=\frac{1}{N}\sum_{n=1}^{N}\sum_{t=0}^{\infty}\hat A_{t}^{n}\nabla_{\theta}log\pi_\theta(a_{t}^{n}|s_{t}^{n})</script>

<p>一个方法是用REINFORCE算法估计$A^{\pi_{\theta}}(s,a)$。下一节使用另一个方法，用函数近似 $V^{\pi_{\theta}}(s)$ 来估计 $A^{\pi_{\theta}}(s,a)$。</p>

<h2 id="advantage-function-estimation">Advantage Function Estimation</h2>
<p>类似于 $TD(\lambda)$ 方法，以下都是 $A^{\pi_{\theta}}(s_{t},a_{t})$ 的估计</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\hat A_{t}^{(1)}&=r_{t}+\gamma V_{\phi}(s_{t+1})-V_{\phi}(s_{t})\\
\hat A_{t}^{(2)}&=r_{t}+\gamma r_{t+1}+\gamma^{2} V_{\phi}(s_{t+2})-V_{\phi}(s_{t})\\
\hat A_{t}^{(3)}&=r_{t}+\gamma r_{t+1}+\gamma^{2} r_{t+2}+\gamma^{3} V_{\phi}(s_{t+3})-V_{\phi}(s_{t})\\
...\\
\hat A_{t}^{(k)}&=r_{t}+\gamma r_{t+1}+...+\gamma^{k-1} r_{t+k-1}+\gamma^{k} V_{\phi}(s_{t+k})-V_{\phi}(s_{t})\\
...\\
\hat A_{t}^{(\infty)}&=\sum_{l=0}^{\infty}\gamma^{l}r_{t+l}-V_{\phi}(s_{t}) \tag{1} \label{A_inf}
\end{align} %]]></script>

<p>其中 $V_{\phi}(s_{t})$ 是value function $V^{\pi_{\theta}}(s_{t})$ 的函数近似。随着k的增加，估计 $\hat A_{t}^{(k)}$ 的variance增加，bias减小。</p>

<p>Generalized Advantage Estimator (GAE)是以上所有估计的exponentially-weighted average，记作 $\hat A_{t}^{GAE(\gamma,\lambda)}$，</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\hat A_{t}^{GAE(\gamma,\lambda)}&=(1-\lambda)(\hat A_{t}^{(1)}+\lambda \hat A_{t}^{(2)}+\lambda^3 \hat A_{t}^{(3)}+...)\\
&=\sum_{l=0}^{\infty}(\gamma\lambda)^{l}\delta_{t+l}^{V_{\phi}}
\end{align} %]]></script>

<p>其中 $\delta_{t+l}^{V_{\phi}}=r_{t+l}+\gamma V_{\phi}(s_{t+l+1})-V_{\phi}(s_{t+l})$，用第二个等式可以方便的计算 $\hat A_{t}^{GAE(\gamma,\lambda)}$。容易看出 $\lambda=0$ 时，$\hat A_{t}^{GAE(\gamma,\lambda)}=\hat A_{t}^{(1)}$；$\lambda=1$ 时，$\hat A_{t}^{GAE(\gamma,\lambda)}=\hat A_{t}^{(\infty)}$。GAE通过exponentially-weighted average进行了bias-variance tradeoff，$\lambda$越大，后面的估计的权重越大，bias越小，variance越大。</p>

<p>以上分别用函数近似了policy和value function，这种方法叫做Actor-Critic算法。有了 $A^{\pi_{\theta}}(s_{t},a_{t})$ 的估计，就可以用policy gradient estimator $\widehat{\nabla_{\theta}J(\theta)}$ 来更新 $\pi_{\theta}(a|s)$ 的参数 $\theta$。那么如何更新 $V_{\phi}(s)$ 的参数 $\phi$？最直观的想法是最小化L2损失</p>

<script type="math/tex; mode=display">\min_{\phi}\sum_{n=1}^{N}\sum_{t=0}^{\infty}(\hat V(s_{t})-V_{\phi}(s_{t}))^2</script>

<p>其中 $\hat V(s_{t})=\sum_{l=0}^{\infty}\gamma^{l}r_{t+l}$。下面的代码使用$\eqref{A_inf}$ 来估计advantage function，使用<a href="http://sebastianruder.com/optimizing-gradient-descent/index.html">mini-batch gradient descent optimization algorithms</a>中的<a href="http://sebastianruder.com/optimizing-gradient-descent/index.html#adam">Adam</a>算法来更新参数 $\phi$。</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">discount</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">scipy</span><span class="o">.</span><span class="n">signal</span><span class="o">.</span><span class="n">lfilter</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="n">gamma</span><span class="p">],</span> <span class="n">x</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">rollout</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">agent</span><span class="p">,</span> <span class="n">max_pathlength</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="p">):</span>
    <span class="n">paths</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">timesteps_sofar</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">timesteps_sofar</span> <span class="o">&lt;</span> <span class="n">n_timesteps</span><span class="p">:</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">action_dists</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="n">ob</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">agent</span><span class="o">.</span><span class="n">prev_action</span> <span class="o">*=</span> <span class="mf">0.0</span>
        <span class="n">agent</span><span class="o">.</span><span class="n">prev_obs</span> <span class="o">*=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">max_pathlength</span><span class="p">):</span>
            <span class="n">action</span><span class="p">,</span> <span class="n">action_dist</span><span class="p">,</span> <span class="n">ob</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">ob</span><span class="p">)</span>
            <span class="n">obs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ob</span><span class="p">)</span>
            <span class="n">actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">action_dists</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action_dist</span><span class="p">)</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">ob</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">res</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
                <span class="n">path</span> <span class="o">=</span> <span class="p">{</span><span class="s">"obs"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span>
                        <span class="s">"action_dists"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">action_dists</span><span class="p">),</span>
                        <span class="s">"rewards"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rewards</span><span class="p">),</span>
                        <span class="s">"actions"</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">actions</span><span class="p">)}</span>
                <span class="n">paths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
                <span class="n">agent</span><span class="o">.</span><span class="n">prev_action</span> <span class="o">*=</span> <span class="mf">0.0</span>
                <span class="n">agent</span><span class="o">.</span><span class="n">prev_obs</span> <span class="o">*=</span> <span class="mf">0.0</span>
                <span class="k">break</span>
        <span class="n">timesteps_sofar</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">path</span><span class="p">[</span><span class="s">"rewards"</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">paths</span>

<span class="k">class</span> <span class="nc">VF</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="n">coeffs</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">session</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">session</span> <span class="o">=</span> <span class="n">session</span>

    <span class="k">def</span> <span class="nf">create_net</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">shape</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">"x"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">"y"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">wrap</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">)</span><span class="o">.</span>
                    <span class="n">fully_connected</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span><span class="o">.</span>
                    <span class="n">fully_connected</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span><span class="o">.</span>
                    <span class="n">fully_connected</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">))</span>
        <span class="n">l2</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">()</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">l2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">initialize_all_variables</span><span class="p">())</span>


    <span class="k">def</span> <span class="nf">_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="n">o</span> <span class="o">=</span> <span class="n">path</span><span class="p">[</span><span class="s">"obs"</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float32'</span><span class="p">)</span>
        <span class="n">o</span> <span class="o">=</span> <span class="n">o</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">o</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">act</span> <span class="o">=</span> <span class="n">path</span><span class="p">[</span><span class="s">"action_dists"</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float32'</span><span class="p">)</span>
        <span class="n">l</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">path</span><span class="p">[</span><span class="s">"rewards"</span><span class="p">])</span>
        <span class="n">al</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">l</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">10.0</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">o</span><span class="p">,</span> <span class="n">act</span><span class="p">,</span> <span class="n">al</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">l</span><span class="p">,</span> <span class="mi">1</span><span class="p">))],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ret</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">paths</span><span class="p">):</span>
        <span class="n">featmat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_features</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">create_net</span><span class="p">(</span><span class="n">featmat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">returns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">path</span><span class="p">[</span><span class="s">"returns"</span><span class="p">]</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">:</span> <span class="n">featmat</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">:</span> <span class="n">returns</span><span class="p">})</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">path</span><span class="p">[</span><span class="s">"rewards"</span><span class="p">]))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_features</span><span class="p">(</span><span class="n">path</span><span class="p">)})</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ret</span><span class="p">,</span> <span class="p">(</span><span class="n">ret</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">))</span>

<span class="err">···</span>

<span class="bp">self</span><span class="o">.</span><span class="n">vf</span> <span class="o">=</span> <span class="n">VF</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">)</span>

<span class="err">···</span>

<span class="c"># Generating paths.</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Rollout"</span><span class="p">)</span>
<span class="n">paths</span> <span class="o">=</span> <span class="n">rollout</span><span class="p">(</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">,</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">config</span><span class="o">.</span><span class="n">max_pathlength</span><span class="p">,</span>
    <span class="n">config</span><span class="o">.</span><span class="n">timesteps_per_batch</span><span class="p">)</span>

<span class="c"># Computing returns and estimating advantage function.</span>
<span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">:</span>
    <span class="n">path</span><span class="p">[</span><span class="s">"baseline"</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">path</span><span class="p">[</span><span class="s">"returns"</span><span class="p">]</span> <span class="o">=</span> <span class="n">discount</span><span class="p">(</span><span class="n">path</span><span class="p">[</span><span class="s">"rewards"</span><span class="p">],</span><span class="n">config</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span>
    <span class="n">path</span><span class="p">[</span><span class="s">"advant"</span><span class="p">]</span> <span class="o">=</span> <span class="n">path</span><span class="p">[</span><span class="s">"returns"</span><span class="p">]</span> <span class="o">-</span> <span class="n">path</span><span class="p">[</span><span class="s">"baseline"</span><span class="p">]</span>

<span class="err">···</span>

<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">vf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">paths</span><span class="p">)</span>
</code></pre>
</div>

<p><a href="https://arxiv.org/abs/1602.01783">A3C</a>算法使用 $\hat A_{t}^{(\infty)}$ 计算 policy gradient，使用mini-batch gradient descent optimization algorithms来更新policy参数和value function参数。</p>

<p><a href="https://arxiv.org/abs/1506.02438">TRPO+GAE</a>算法使用 $\hat A_{t}^{GAE(\gamma,\lambda)}$ 计算 policy gradient，使用TRPO算法来更新policy参数，使用trust region method来更新value function参数。</p>

<p>下一节将结合代码详细讲解TRPO算法。</p>

<h2 id="trust-region-policy-optimization">Trust Region Policy Optimization</h2>
<p>当使用<a href="http://sebastianruder.com/optimizing-gradient-descent/index.html">mini-batch gradient descent optimization algorithms</a>来更新参数时，需要给定learning rate，i.e. step size。PG算法中的step size的选取是极其重要的！因为step size决定了下一次抽样的策略函数，如果step size选的不好，下一次的mini-batch就会从很差的策略里产生。不同于supervise learning，因为训练样本早就确定了，即使这次step size步子扯大了，下个mini-batch还能扯回来。现在的难点在于PG算法只给出了梯度的估计，并没有目标函数可以用来进行<a href="https://en.wikipedia.org/wiki/Line_search">line search</a>以确定好的step size。借鉴<a href="https://www.youtube.com/watch?v=P0Rhzv9GfYs">trust region method</a>的想法，如果可以给出目标函数 $J(\theta)$ 的局部近似函数，这个函数在trust region中是目标函数的一个很好的近似, 那就可以在trust region中最大化近似函数来更新参数 $\theta$。</p>

<p>令</p>

<script type="math/tex; mode=display">L_{\theta_{old}}(\theta)=J(\theta_{old})+E_{\pi_{\theta_{old}}}[\frac{\pi_{\theta}(a|s)}{\pi_{\theta_{old}}(a|s)}A_{\pi_{\theta_{old}}}(s,a)]，</script>

<p>有</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
L_{\theta_{old}}(\theta_{old})&=J(\theta_{old})+E_{\pi_{\theta_{old}}}[A_{\pi_{\theta_{old}}}(s,a)]  \\
&=J(\theta_{old})
\end{align} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\nabla L_{\theta_{old}}(\theta)\big |_{\theta=\theta_{old}}&=E_{\pi_{\theta_{old}}}[\frac{\nabla\pi_{\theta}(a|s)\big |_{\theta=\theta_{old}}}{\pi_{\theta_{old}}(a|s)}A_{\pi_{\theta_{old}}}(s,a)] \\
&=E_{\pi_{\theta}}[\nabla log\pi_{\theta}(a|s)A_{\pi_{\theta}}(s,a)]\big |_{\theta=\theta_{old}} \\
&=\nabla J(\theta)\big |_{\theta=\theta_{old}}
\end{align} %]]></script>

<p>所以 $L_{\theta_{old}}(\theta)$ 为 $J(\theta)$ 在 $\theta_{old}$ 附近的近似函数。</p>

<p>文章<a href="https://arxiv.org/abs/1502.05477">Trust Region Policy Optimization</a>证明了如下定理,</p>

<script type="math/tex; mode=display">J(\theta)\ge L_{\theta_{old}}(\theta)-CD_{KL}^{max}(\theta_{old},\theta)</script>

<p>其中，</p>

<script type="math/tex; mode=display">C=\frac{2\epsilon\gamma}{(1-\gamma)^2},</script>

<script type="math/tex; mode=display">D_{KL}^{max}(\theta_{old},\theta)=\max_{s}D_{KL}(\pi_{\theta_{old}}(·|s)\|\pi_{\theta}(·|s)).</script>

<p>想利用上面的定理来更新参数有如下困难。由于 $\gamma$ 通常取较大值，因而 penalty coefficient $C$ 会很大，导致step size非常小。解决方法是将penalty项转变成对<a href="https://en.wikipedia.org/wiki/Kullback–Leibler_divergence">KL divergence</a>的约束，即一个trust region，问题转化为，</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
&\max_\theta L_{\theta_{old}}(\theta) \\
&\text{ subjec to }D_{KL}^{max}(\theta_{old},\theta)\le \delta.
\end{align} %]]></script>

<p>观察约束条件，对状态空间中的每一个状态，都有KL divergence的约束，这么多约束条件在实际计算中是不可行的。直观上的一个解决办法是，使用average来代替max，将多个约束条件转换成一个约束条件，实验结果也表明这个代替有相似的实验表现，因此是可行的。用下面的带约束的优化问题来更新policy参数，</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
&\max_\theta L_{\theta_{old}}(\theta) \\
&\text{ subjec to }D_{KL}^{ave(\theta_{old})}(\theta_{old},\theta)\le \delta.
\end{align} %]]></script>

<p>其中，</p>

<script type="math/tex; mode=display">D_{KL}^{ave(\theta_{old})}(\theta_{old},\theta)=E_{\pi_{\theta_{old}}}[D_{KL}\left (\pi_{\theta_{old}}(·|s)\|\pi_{\theta}(·|s)\right)].</script>

<p>在当前policy $\pi_{\theta_{old}}$ 抽样mini-batch trajectories来估计目标函数和约束函数，有</p>

<script type="math/tex; mode=display">\hat L_{\theta_{old}}(\theta)=\frac{1}{N}\sum_{n=1}^{N}\sum_{t=0}^{\infty}\frac{\pi_\theta(a_{t}^{n}|s_{t}^{n})}{\pi_{\theta_{old}}(a_{t}^{n}|s_{t}^{n})}\hat A_{t}^{n}</script>

<script type="math/tex; mode=display">\hat D_{KL}^{ave(\theta_{old})}(\theta_{old},\theta)=\frac{1}{N}\sum_{n=1}^{N}\sum_{t=0}^{\infty}D_{KL}\left (\pi_{\theta_{old}}(·|s_{t}^{n})\|\pi_{\theta}(·|s_{t}^{n})\right)</script>

<p>这里的 $\hat A_{t}^{n}$ 用 $\eqref{A_inf}$ 式计算，已在上一段面的代码中给出。</p>

<p>这个带约束的优化问题怎么解啊喂！文章教我们首先用目标函数的一阶近似和约束函数的二阶近似来计算 $\Delta\theta=\theta-\theta_{old}$ 的方向，然后用<a href="https://en.wikipedia.org/wiki/Backtracking_line_search">Backtracking line search</a>来确定step size，使得目标函数增大的同时满足约束条件。</p>

<p>KL divergence与Fisher information matrix有如下关系(<a href="http://stats.stackexchange.com/questions/51185/connection-between-fisher-metric-and-the-relative-entropy">证明</a>)，</p>

<script type="math/tex; mode=display">D_{KL}\left (\pi_{\theta_{old}}(·|s)\|\pi_{\theta}(·|s)\right)=\frac{1}{2}\Delta\theta^TI(\theta_{old})\Delta\theta+
\mathcal{O}(\|\Delta\theta\|^3)</script>

<p>其中，</p>

<script type="math/tex; mode=display">I(\theta)=E_{\pi_\theta}[\nabla_\theta log\pi_\theta(·|s)\nabla_\theta log\pi_\theta(·|s)^T]</script>

<p>为Fisher information matrix。由上式知，KL divergence的一阶导为 $0$，$I(\theta)$ 等于KL divergence的Hessian矩阵。为什么用Hessian矩阵而不用Fisher information matrix来近似KL divergence呢？因为好计算啊！Tensorflow自带的求导功能使得Hessian矩阵的计算非常简单。</p>

<p>近似后的优化问题变为，</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
&\max_{\Delta \theta} \Delta\theta^T\nabla_{\theta}L_{\theta_{old}}(\theta_{old}+\Delta \theta)\big |_{\theta=\theta_{old}}\\
&\text{ subjec to } \frac{1}{2}\Delta\theta^TH(\theta)\big |_{\theta=\theta_{old}}\Delta\theta\le \delta.
\end{align} %]]></script>

<p>其中 $H(\theta)$ 是 $\hat D_{KL}^{ave(\theta_{old})}(\theta_{old},\theta)$ 的Hessian矩阵。</p>

<p>用Tensorflow的求导功能很容易计算目标函数一阶导和约束函数的Hessian矩阵，记作 $g$ 和 $A$。</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TRPOAgent</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

<span class="o">...</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">env</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">Box</span><span class="p">)</span> <span class="ow">or</span> \
           <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="n">Discrete</span><span class="p">):</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"Incompatible spaces."</span><span class="p">)</span>
            <span class="nb">exit</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Observation Space"</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Action Space"</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">session</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span>
            <span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span>
                <span class="bp">None</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">"obs"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prev_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prev_action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action</span> <span class="o">=</span> <span class="n">action</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">"action"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">advant</span> <span class="o">=</span> <span class="n">advant</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">"advant"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">oldaction_dist</span> <span class="o">=</span> <span class="n">oldaction_dist</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">"oldaction_dist"</span><span class="p">)</span>

        <span class="c"># Create neural network.</span>
        <span class="n">action_dist_n</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">wrap</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">obs</span><span class="p">)</span><span class="o">.</span>
                            <span class="n">fully_connected</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">tanh</span><span class="p">)</span><span class="o">.</span>
                            <span class="n">softmax_classifier</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span><span class="p">))</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-6</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_dist_n</span> <span class="o">=</span> <span class="n">action_dist_n</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">obs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">p_n</span> <span class="o">=</span> <span class="n">slice_2d</span><span class="p">(</span><span class="n">action_dist_n</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">action</span><span class="p">)</span>
        <span class="n">oldp_n</span> <span class="o">=</span> <span class="n">slice_2d</span><span class="p">(</span><span class="n">oldaction_dist</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">action</span><span class="p">)</span>
        <span class="n">ratio_n</span> <span class="o">=</span> <span class="n">p_n</span> <span class="o">/</span> <span class="n">oldp_n</span>
        <span class="n">Nf</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="n">surr</span> <span class="o">=</span> <span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">ratio_n</span> <span class="o">*</span> <span class="n">advant</span><span class="p">)</span>  <span class="c"># Surrogate loss就是L</span>
        <span class="n">var_list</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()</span>
        <span class="n">kl</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">oldaction_dist</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="n">oldaction_dist</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">action_dist_n</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)))</span> <span class="o">/</span> <span class="n">Nf</span>
        <span class="n">ent</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="o">-</span><span class="n">action_dist_n</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">action_dist_n</span> <span class="o">+</span> <span class="n">eps</span><span class="p">))</span> <span class="o">/</span> <span class="n">Nf</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">surr</span><span class="p">,</span> <span class="n">kl</span><span class="p">,</span> <span class="n">ent</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pg</span> <span class="o">=</span> <span class="n">flatgrad</span><span class="p">(</span><span class="n">surr</span><span class="p">,</span> <span class="n">var_list</span><span class="p">)</span>
        <span class="c"># KL divergence where first arg is fixed</span>
        <span class="c"># replace old-&gt;tf.stop_gradient from previous kl</span>
        <span class="n">kl_firstfixed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span>
            <span class="n">action_dist_n</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">action_dist_n</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">action_dist_n</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)))</span> <span class="o">/</span> <span class="n">Nf</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">kl_firstfixed</span><span class="p">,</span> <span class="n">var_list</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flat_tangent</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">])</span>
        <span class="n">shapes</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">var_shape</span><span class="p">,</span> <span class="n">var_list</span><span class="p">)</span>
        <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">tangents</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">shape</span> <span class="ow">in</span> <span class="n">shapes</span><span class="p">:</span>
            <span class="n">size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">param</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flat_tangent</span><span class="p">[</span><span class="n">start</span><span class="p">:(</span><span class="n">start</span> <span class="o">+</span> <span class="n">size</span><span class="p">)],</span> <span class="n">shape</span><span class="p">)</span>
            <span class="n">tangents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
            <span class="n">start</span> <span class="o">+=</span> <span class="n">size</span>
        <span class="n">gvp</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">g</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">tangents</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fvp</span> <span class="o">=</span> <span class="n">flatgrad</span><span class="p">(</span><span class="n">gvp</span><span class="p">,</span> <span class="n">var_list</span><span class="p">)</span>  
        <span class="bp">self</span><span class="o">.</span><span class="n">gf</span> <span class="o">=</span> <span class="n">GetFlat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">,</span> <span class="n">var_list</span><span class="p">)</span>   <span class="c">#获取参数值</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sff</span> <span class="o">=</span> <span class="n">SetFromFlat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">,</span> <span class="n">var_list</span><span class="p">)</span>  <span class="c">#设置参数值</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vf</span> <span class="o">=</span> <span class="n">VF</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">)</span>  <span class="c">#</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">initialize_all_variables</span><span class="p">())</span>        
</code></pre>
</div>

<p>用<a href="http://blog.csdn.net/huanongjingchao/article/details/17298569">拉格朗日乘子法和KKT条件</a>求解上面带约束的优化问题，容易得到解为 $\Delta \theta=\alpha_{max}\cdot s$，其中 $s=A^{-1}(-g)$ 是更新方向。$\alpha_{max}=\sqrt{\frac{2\delta}{s^TAs}}$ 是step size，这个step size是一阶近似目标函数的情况下得到的，是满足约束条件的最大的step size。可以用<a href="https://en.wikipedia.org/wiki/Backtracking_line_search">Backtracking line search</a> 缩小step size，使得原始目标函数 $\hat L_{\theta_{old}}(\theta_{old}+\Delta \theta)$ 有足够的优化，同时仍然满足约束条件。</p>

<p>观察 $s=A^{-1}(-g)$，要计算更新方向 $s$，必须计算Hessian矩阵 $A$  的逆，当参数特别多时（例如用neural network来表示policy时），$A$ 的维度很高，求逆计算不可行。要计算 $s$，即求解方程 $As=-g$。<strong>Here comes the trick！</strong> 用<a href="https://en.wikipedia.org/wiki/Conjugate_gradient_method">conjugate gradient method</a> 近似求解方程，不需要求逆，只需要有个函数可以计算矩阵-向量乘积 $y\rightarrow Ay$ 即可。</p>

<p>下面是求解方程 $Ax=b$ 的<a href="https://en.wikipedia.org/wiki/Conjugate_gradient_method#The_resulting_algorithm">Conjugate Gradient Algorithm</a>，其中 $A$ 为实对称正定矩阵。</p>

<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e300dfefdbd374cdee765397528a65a5736a50d3" alt="Conjugate Gradient Algorithm" /></p>

<p>这是最常用的Conjugate Gradient Algorithm。算法的直观解释参见<a href="https://www.youtube.com/watch?v=h4cG8jLGmKg&amp;list=PLKP6-DnQsS-JfEjRhtDznV4L38znQ1PGw&amp;index=9">Conjugate Gradient Method</a>和<a href="https://www.youtube.com/watch?v=eAYohMUpPMA&amp;list=PLKP6-DnQsS-JfEjRhtDznV4L38znQ1PGw&amp;index=8">Overview of Conjugate Gradient Method</a>，算法的推导过程参见<a href="https://en.wikipedia.org/wiki/Derivation_of_the_conjugate_gradient_method">Derivation of the conjugate gradient method</a>。</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">conjugate_gradient</span><span class="p">(</span><span class="n">f_Ax</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">cg_iters</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">residual_tol</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">rdotr</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">cg_iters</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">f_Ax</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">rdotr</span> <span class="o">/</span> <span class="n">p</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">+=</span> <span class="n">v</span> <span class="o">*</span> <span class="n">p</span>
        <span class="n">r</span> <span class="o">-=</span> <span class="n">v</span> <span class="o">*</span> <span class="n">z</span>
        <span class="n">newrdotr</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">newrdotr</span> <span class="o">/</span> <span class="n">rdotr</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">r</span> <span class="o">+</span> <span class="n">mu</span> <span class="o">*</span> <span class="n">p</span>
        <span class="n">rdotr</span> <span class="o">=</span> <span class="n">newrdotr</span>
        <span class="k">if</span> <span class="n">rdotr</span> <span class="o">&lt;</span> <span class="n">residual_tol</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="err">···</span>

<span class="k">def</span> <span class="nf">fisher_vector_product</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="n">feed</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">flat_tangent</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fvp</span><span class="p">,</span> <span class="n">feed</span><span class="p">)</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">cg_damping</span> <span class="o">*</span> <span class="n">p</span>

<span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pg</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>
<span class="n">stepdir</span> <span class="o">=</span> <span class="n">conjugate_gradient</span><span class="p">(</span><span class="n">fisher_vector_product</span><span class="p">,</span> <span class="o">-</span><span class="n">g</span><span class="p">)</span>                  
</code></pre>
</div>

<p>有了更新方向 $s$，下面用<a href="https://en.wikipedia.org/wiki/Backtracking_line_search">Backtracking line search</a> 选取合适的step size，使得目标函数充分的增大。</p>

<ol>
  <li>令 $\alpha=\alpha_{max}=\sqrt{\frac{2\delta}{s^TAs}}$，$\tau=0.5$，$c=0.1$</li>
  <li>重复 $\alpha\leftarrow \tau\alpha$ 直到 $\hat L_{\theta_{old}}(\theta_{old}+\alpha s)-\hat L_{\theta_{old}}(\theta_{old})\ge \alpha cm$，其中 $m=\nabla_\alpha \hat L_{\theta_{old}}(\theta_{old}+\alpha s)=s^T(-g)$</li>
  <li>返回 $\alpha$</li>
</ol>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">linesearch</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">fullstep</span><span class="p">,</span> <span class="n">expected_improve_rate</span><span class="p">):</span>
    <span class="n">accept_ratio</span> <span class="o">=</span> <span class="o">.</span><span class="mi">1</span>
    <span class="n">max_backtracks</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">fval</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">_n_backtracks</span><span class="p">,</span> <span class="n">stepfrac</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="o">.</span><span class="mi">5</span><span class="o">**</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_backtracks</span><span class="p">)):</span>
        <span class="n">xnew</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">stepfrac</span> <span class="o">*</span> <span class="n">fullstep</span>
        <span class="n">newfval</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">xnew</span><span class="p">)</span>
        <span class="n">actual_improve</span> <span class="o">=</span> <span class="n">fval</span> <span class="o">-</span> <span class="n">newfval</span>
        <span class="n">expected_improve</span> <span class="o">=</span> <span class="n">expected_improve_rate</span> <span class="o">*</span> <span class="n">stepfrac</span>
        <span class="n">ratio</span> <span class="o">=</span> <span class="n">actual_improve</span> <span class="o">/</span> <span class="n">expected_improve</span>
        <span class="k">if</span> <span class="n">ratio</span> <span class="o">&gt;</span> <span class="n">accept_ratio</span> <span class="ow">and</span> <span class="n">actual_improve</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">xnew</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="err">···</span>

<span class="n">shs</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">stepdir</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">fisher_vector_product</span><span class="p">(</span><span class="n">stepdir</span><span class="p">))</span>
<span class="n">lm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">shs</span> <span class="o">/</span> <span class="n">config</span><span class="o">.</span><span class="n">max_kl</span><span class="p">)</span>
<span class="n">fullstep</span> <span class="o">=</span> <span class="n">stepdir</span> <span class="o">/</span> <span class="n">lm</span>
<span class="n">neggdotstepdir</span> <span class="o">=</span> <span class="o">-</span><span class="n">g</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">stepdir</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">th</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sff</span><span class="p">(</span><span class="n">th</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>

<span class="n">theta</span> <span class="o">=</span> <span class="n">linesearch</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">thprev</span><span class="p">,</span> <span class="n">fullstep</span><span class="p">,</span> <span class="n">neggdotstepdir</span> <span class="o">/</span> <span class="n">lm</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">sff</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
</code></pre>
</div>

<p>下面的代码是完整的训练过程。</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TRPOAgent</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

<span class="err">···</span>

    <span class="k">def</span> <span class="nf">learn</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">numeptotal</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="c"># Generating paths.</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"Rollout"</span><span class="p">)</span>
            <span class="n">paths</span> <span class="o">=</span> <span class="n">rollout</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">,</span>
                <span class="bp">self</span><span class="p">,</span>
                <span class="n">config</span><span class="o">.</span><span class="n">max_pathlength</span><span class="p">,</span>
                <span class="n">config</span><span class="o">.</span><span class="n">timesteps_per_batch</span><span class="p">)</span>

            <span class="c"># Computing returns and estimating advantage function.</span>
            <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">:</span>
                <span class="n">path</span><span class="p">[</span><span class="s">"baseline"</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
                <span class="n">path</span><span class="p">[</span><span class="s">"returns"</span><span class="p">]</span> <span class="o">=</span> <span class="n">discount</span><span class="p">(</span><span class="n">path</span><span class="p">[</span><span class="s">"rewards"</span><span class="p">],</span> <span class="n">config</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span>
                <span class="n">path</span><span class="p">[</span><span class="s">"advant"</span><span class="p">]</span> <span class="o">=</span> <span class="n">path</span><span class="p">[</span><span class="s">"returns"</span><span class="p">]</span> <span class="o">-</span> <span class="n">path</span><span class="p">[</span><span class="s">"baseline"</span><span class="p">]</span>

            <span class="c"># Updating policy.</span>
            <span class="n">action_dist_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">path</span><span class="p">[</span><span class="s">"action_dists"</span><span class="p">]</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">])</span>
            <span class="n">obs_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">path</span><span class="p">[</span><span class="s">"obs"</span><span class="p">]</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">])</span>
            <span class="n">action_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">path</span><span class="p">[</span><span class="s">"actions"</span><span class="p">]</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">])</span>
            <span class="n">baseline_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">path</span><span class="p">[</span><span class="s">"baseline"</span><span class="p">]</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">])</span>
            <span class="n">returns_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">path</span><span class="p">[</span><span class="s">"returns"</span><span class="p">]</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">])</span>

            <span class="c"># Standardize the advantage function to have mean=0 and std=1.</span>
            <span class="n">advant_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">path</span><span class="p">[</span><span class="s">"advant"</span><span class="p">]</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">])</span>
            <span class="n">advant_n</span> <span class="o">-=</span> <span class="n">advant_n</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

            <span class="c"># Computing baseline function for next iter.</span>

            <span class="n">advant_n</span> <span class="o">/=</span> <span class="p">(</span><span class="n">advant_n</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>

            <span class="n">feed</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">obs</span><span class="p">:</span> <span class="n">obs_n</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">action</span><span class="p">:</span> <span class="n">action_n</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">advant</span><span class="p">:</span> <span class="n">advant_n</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">oldaction_dist</span><span class="p">:</span> <span class="n">action_dist_n</span><span class="p">}</span>


            <span class="n">episoderewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                <span class="p">[</span><span class="n">path</span><span class="p">[</span><span class="s">"rewards"</span><span class="p">]</span><span class="o">.</span><span class="nb">sum</span><span class="p">()</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">])</span>

            <span class="k">print</span> <span class="s">"</span><span class="se">\n</span><span class="s">********** Iteration </span><span class="si">%</span><span class="s">i ************"</span> <span class="o">%</span> <span class="n">i</span>
            <span class="k">if</span> <span class="n">episoderewards</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">1.1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">_env</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">reward_threshold</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="s">"Episode mean: </span><span class="si">%</span><span class="s">f"</span> <span class="o">%</span> <span class="n">episoderewards</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">end_count</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_count</span> <span class="o">&gt;</span> <span class="mi">100</span><span class="p">:</span>
                    <span class="k">break</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">vf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">paths</span><span class="p">)</span>
                <span class="n">thprev</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gf</span><span class="p">()</span>

                <span class="k">def</span> <span class="nf">fisher_vector_product</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
                    <span class="n">feed</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">flat_tangent</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fvp</span><span class="p">,</span> <span class="n">feed</span><span class="p">)</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">cg_damping</span> <span class="o">*</span> <span class="n">p</span>

                <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pg</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>
                <span class="n">stepdir</span> <span class="o">=</span> <span class="n">conjugate_gradient</span><span class="p">(</span><span class="n">fisher_vector_product</span><span class="p">,</span> <span class="o">-</span><span class="n">g</span><span class="p">)</span>
                <span class="n">shs</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">stepdir</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">fisher_vector_product</span><span class="p">(</span><span class="n">stepdir</span><span class="p">))</span>
                <span class="n">lm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">shs</span> <span class="o">/</span> <span class="n">config</span><span class="o">.</span><span class="n">max_kl</span><span class="p">)</span>
                <span class="n">fullstep</span> <span class="o">=</span> <span class="n">stepdir</span> <span class="o">/</span> <span class="n">lm</span>
                <span class="n">neggdotstepdir</span> <span class="o">=</span> <span class="o">-</span><span class="n">g</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">stepdir</span><span class="p">)</span>

                <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">th</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">sff</span><span class="p">(</span><span class="n">th</span><span class="p">)</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>
                <span class="n">theta</span> <span class="o">=</span> <span class="n">linesearch</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">thprev</span><span class="p">,</span> <span class="n">fullstep</span><span class="p">,</span> <span class="n">neggdotstepdir</span> <span class="o">/</span> <span class="n">lm</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">sff</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

                <span class="n">surrafter</span><span class="p">,</span> <span class="n">kloldnew</span><span class="p">,</span> <span class="n">entropy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">kloldnew</span> <span class="o">&gt;</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">max_kl</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">sff</span><span class="p">(</span><span class="n">thprev</span><span class="p">)</span>

                <span class="n">stats</span> <span class="o">=</span> <span class="p">{}</span>

                <span class="n">numeptotal</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">episoderewards</span><span class="p">)</span>
                <span class="n">stats</span><span class="p">[</span><span class="s">"Total number of episodes"</span><span class="p">]</span> <span class="o">=</span> <span class="n">numeptotal</span>
                <span class="n">stats</span><span class="p">[</span><span class="s">"Average sum of rewards per episode"</span><span class="p">]</span> <span class="o">=</span> <span class="n">episoderewards</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
                <span class="n">stats</span><span class="p">[</span><span class="s">"Entropy"</span><span class="p">]</span> <span class="o">=</span> <span class="n">entropy</span>
                <span class="n">exp</span> <span class="o">=</span> <span class="n">explained_variance</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">baseline_n</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">returns_n</span><span class="p">))</span>
                <span class="n">stats</span><span class="p">[</span><span class="s">"Baseline explained"</span><span class="p">]</span> <span class="o">=</span> <span class="n">exp</span>
                <span class="n">stats</span><span class="p">[</span><span class="s">"Time elapsed"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"</span><span class="si">%.2</span><span class="s">f mins"</span> <span class="o">%</span> <span class="p">((</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">/</span> <span class="mf">60.0</span><span class="p">)</span>
                <span class="n">stats</span><span class="p">[</span><span class="s">"KL between old and new distribution"</span><span class="p">]</span> <span class="o">=</span> <span class="n">kloldnew</span>
                <span class="n">stats</span><span class="p">[</span><span class="s">"Surrogate loss"</span><span class="p">]</span> <span class="o">=</span> <span class="n">surrafter</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">stats</span><span class="o">.</span><span class="n">iteritems</span><span class="p">():</span>
                    <span class="k">print</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="s">": "</span> <span class="o">+</span> <span class="s">" "</span> <span class="o">*</span> <span class="p">(</span><span class="mi">40</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">k</span><span class="p">))</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
                <span class="k">if</span> <span class="n">entropy</span> <span class="o">!=</span> <span class="n">entropy</span><span class="p">:</span>
                    <span class="nb">exit</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">exp</span> <span class="o">&gt;</span> <span class="mf">0.8</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre>
</div>

<p>至此TRPO算法全部推导完成啦！更多代码细节可以<a href="https://github.com/wojzaremba/trpo">查看完整代码</a>。</p>




  <!-- Share -->
  
  <div class="post-share">
    <hr>
    <span>Share this: <br /></span>
<a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/2016-11-09/trpo-code-analysis/" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" class="ssk ssk-icon ssk-facebook"></a>
<a href="https://twitter.com/intent/tweet?text=TRPO算法与代码解析&url=http://localhost:4000/2016-11-09/trpo-code-analysis/" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" class="ssk ssk-icon ssk-twitter"></a>
<a href="https://plus.google.com/share?url=http://localhost:4000/2016-11-09/trpo-code-analysis/" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" class="ssk ssk-icon ssk-google-plus"></a>
<a href="https://www.tumblr.com/share?url=http://localhost:4000/2016-11-09/trpo-code-analysis/" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" class="ssk ssk-icon ssk-tumblr"></a>
<a href="mailto:?subject=TRPO算法与代码解析&amp;body=Check out this site http://localhost:4000/2016-11-09/trpo-code-analysis/" class="ssk ssk-icon ssk-email"></a>

    <hr>
  </div>
  

  <!-- Disqus -->
  
  <section id="disqus_thread"></section>
  <script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//namiyao.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

  

</div>


    <!-- Documents about icons are here: http://fontawesome.io/icons/ -->
<div class="footer">
	<hr />
	<div class="footer-link">
		

		

		

		

		

		

		
		<a href="mailto:disneydsy@gmail.com"><i class="fa fa-envelope" aria-hidden="true"></i></a>
		

	</div>
<!--	© 2016 Namiyao. All rights reserved.   -->
	Namiyao
</div>

  </div>
</body>
</html>
